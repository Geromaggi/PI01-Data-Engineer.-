{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from  ETL_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leamos cada uno de los archivos y transformemoslos a todos a .csv\n",
    "\n",
    "df_json = pd.read_json('/home/gero/Documentos/HENRY/LAB I/PI01_DATA_ENGINEERING/Datasets/precios_semana_20200503.json')\n",
    "df_txt = pd.read_csv('/home/gero/Documentos/HENRY/LAB I/PI01_DATA_ENGINEERING/Datasets/precios_semana_20200518.txt',delimiter='|')\n",
    "df_csv = pd.read_csv('/home/gero/Documentos/HENRY/LAB I/PI01_DATA_ENGINEERING/Datasets/precios_semana_20200413.csv',encoding='utf_16')\n",
    "\n",
    "df_products_parquet = pd.read_parquet('/home/gero/Documentos/HENRY/LAB I/PI01_DATA_ENGINEERING/Datasets/producto.parquet',engine='pyarrow')\n",
    "df_sucursales = pd.read_csv('/home/gero/Documentos/HENRY/LAB I/PI01_DATA_ENGINEERING/Datasets/sucursal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hojas del excel. \n",
    "hoja1 = 'precios_20200426_20200426'\n",
    "hoja2 = 'precios_20200419_20200419'\n",
    "df_excel_semana_426 = pd.read_excel('/home/gero/Documentos/HENRY/LAB I/PI01_DATA_ENGINEERING/Datasets/precios_semanas_20200419_20200426.xlsx',sheet_name=hoja1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_semana_419 = pd.read_excel('/home/gero/Documentos/HENRY/LAB I/PI01_DATA_ENGINEERING/Datasets/precios_semanas_20200419_20200426.xlsx',sheet_name=hoja2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apliquemos nuestras funciones ETL para cada dataframe. \n",
    "df_products_parquet = etl_productos(df_products_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sucursales = elt_sucursal(df_sucursales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = etl_precios(df_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txt = etl_precios(df_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a partir de aqui veremos que ademas de aplicarle la respectiva funcion ETL a cada dataframe, se le haran algunas otras modificaciones especificas para ese df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json['producto_id'] = df_json['producto_id'].astype(str)# nos convierte la columna producto_id a tipo string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json['producto_id'] = [i.lstrip('0') for i in df_json['producto_id']] #nos saca los ceros a al izquierda de la columna producto_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = etl_precios(df_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_semana_419.sucursal_id = df_excel_semana_419.sucursal_id.apply(lambda _ : str(_)) #convertimos a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_semana_419['sucursal_id'] = df_excel_semana_419['sucursal_id'].apply(lambda x: x.split(' ')[0]) #nos saca la hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_semana_419['producto_id'] = df_excel_semana_419['producto_id'].astype(str).str.split('.',expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_semana_419 = etl_precios(df_excel_semana_419)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_semana_426['producto_id'] = df_excel_semana_426['producto_id'].astype(str).str.split('.',expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "producto_id ya esta limpio\n"
     ]
    }
   ],
   "source": [
    "df_excel_semana_426 = etl_precios(df_excel_semana_426) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminada la limpieza de los datos, lo que haremos ahora sera unir las tablas que contienen los precios, los id_sucursales y los id_producto. \n",
    "# Vemos aqui abajo que usamos el metodo concat para unir todos los dataframes correspondientes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2217125"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precios = pd.concat([df_json,df_txt,df_csv,df_excel_semana_426,df_excel_semana_419],axis=0)\n",
    "precios.shape[0] #la tabla precios contiene aproximadamente 2 millones de registros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ya terminado todo el proceso de transformacion, empezemos nuestra carga a la base de datos mysql. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sql import *\n",
    "#importamos el script de la conexion a mysql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conectamos los 3 df que nos quedaron a mysql. \n",
    "precios.to_sql('precios',conexion,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sucursales.to_sql('sucursales',conexion,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products_parquet.to_sql('productos',conexion,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
